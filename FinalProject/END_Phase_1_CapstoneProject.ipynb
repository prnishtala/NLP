{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END Phase 1_CapstoneProject",
      "provenance": [],
      "authorship_tag": "ABX9TyN3PWtoMC5bAcWy+RoI68Gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb685de4df9041cf834e9e5b2ae5c8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c596078e08e4d4b833c7f25f44521f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f3dda8e79a343ebbaf1c89369fedb98",
              "IPY_MODEL_90451e2d9f87463f858a93bf2f5ea1f6"
            ]
          }
        },
        "0c596078e08e4d4b833c7f25f44521f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f3dda8e79a343ebbaf1c89369fedb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a727555182204a81b23c490bf6ec2d1a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11795,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11795,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60ec1abeada94b3ba2fdfef284661b2b"
          }
        },
        "90451e2d9f87463f858a93bf2f5ea1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b767b5aad2234618b45305cca0d4164e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11795/11795 [06:53&lt;00:00, 28.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0e5c4d7e67b4eb99f8042d11e316567"
          }
        },
        "a727555182204a81b23c490bf6ec2d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60ec1abeada94b3ba2fdfef284661b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b767b5aad2234618b45305cca0d4164e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0e5c4d7e67b4eb99f8042d11e316567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prnishtala/NLP/blob/main/FinalProject/END_Phase_1_CapstoneProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfBDTt4dJCRI"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFS3F6-KIaXO",
        "outputId": "10ae313a-bd81-49a6-888a-4a0b34760641"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset, Dataset, Example\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
        "import torch.nn.functional as F\n",
        "import keyword, token, tokenize\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.set_deterministic(True)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
            "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP5MKsU_IscR"
      },
      "source": [
        "# Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzJyubE4JH_N",
        "outputId": "bc5c8457-ea6b-4ef4-d9b5-c548921fabfe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! cp \"/content/drive/My Drive/NLP/english_python_data_raw.txt\" english_python_data.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_hmqkDOkL7"
      },
      "source": [
        "# Read the file and remove the unwanted data\n",
        "# Removed few anomalies manually to prevent over-engineering\n",
        "\n",
        "with open('english_python_data.txt', 'r') as f:\n",
        "  raw_data = f.readlines()\n",
        "\n",
        "cleansed_data = []\n",
        "\n",
        "for sentence in raw_data:\n",
        "  # Remove the comments indicating beginning of Driver Codes\n",
        "  if re.search(r'^\\s*#\\s+driver', sentence.lower()):\n",
        "    continue\n",
        "  # Remove the unwanted empty lines\n",
        "  elif re.search(r'^\\s*\\n+\\s*$', sentence.lower()):\n",
        "    continue\n",
        "  # Remove the comments in the pattern of \"In[0-9]\"\n",
        "  elif re.search(r'^\\s*#\\s+in\\[[0-9]+\\]', sentence.lower()):\n",
        "    continue\n",
        "  # Remove the comments containing just the numbers\n",
        "  elif re.search(r'^\\s*#+\\s*[0-9]*\\s*\\n', sentence.lower()):\n",
        "    continue\n",
        "  else:\n",
        "    cleansed_data.append(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08XoaJ4EuOvX"
      },
      "source": [
        "# Generate DataFrame from the Input Data\n",
        "\n",
        "df = pd.DataFrame(columns = ['src', 'trg'])\n",
        "\n",
        "src = ''\n",
        "trg = ''\n",
        "minimum_length = 30\n",
        "\n",
        "for i,record in enumerate(cleansed_data):\n",
        "  if record.startswith('#') and len(record) > minimum_length:\n",
        "    df.loc[len(df)] = [src,trg]\n",
        "    trg = ''\n",
        "    src = record\n",
        "  else:\n",
        "    trg = trg + record\n",
        "\n",
        "df = df.iloc[1:]\n",
        "df = df.reset_index(drop=True)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p19CF2b8xENM",
        "outputId": "12b6bfea-6af7-4740-b1a6-7112694167de"
      },
      "source": [
        "file = open('english_python_data.txt',\"rt\", encoding='latin')\n",
        "data_complete = file.read()\n",
        "data_complete =  data_complete.lower()\n",
        "\n",
        "data_complete = re.sub(r'\"#[0123456789]','#', data_complete)\n",
        "data_complete = data_complete.replace(\"\\n\\n\",\"\\n\")\n",
        "data_complete = data_complete.replace(\"\\n\\n\\n\",\"\\n\\n\")\n",
        "\n",
        "data_com = data_complete.split('#')\n",
        "\n",
        "src = []\n",
        "trg =[]\n",
        "\n",
        "for each_code in data_com:\n",
        "    pr_text = each_code.split('\\n')\n",
        "    src.append(pr_text[0])\n",
        "    trg.append(pr_text[1:])\n",
        "\n",
        "df = pd.DataFrame({'src': src, 'trg': trg})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# write a python program to add two numbers\n",
            "num1 = 1.5\n",
            "num2 = 6.3\n",
            "sum = num1 + num2\n",
            "print(f'Sum: {sum}')\n",
            "\n",
            "\n",
            "# write a python function to add two user provided numbers and return the sum\n",
            "def add_two_numbers(num1, num2):\n",
            "    sum = num1 + num2\n",
            "    return sum\n",
            "\n",
            "\n",
            "# write a program to find and print the largest among three numbers\n",
            "\n",
            "num1 = 10\n",
            "num2 = 12\n",
            "num3 = 14\n",
            "if (num1 >= num2) and (num1 >= num3):\n",
            "   largest = num1\n",
            "elif (num2 >= num1) and (num2 >= num3):\n",
            "   largest = num2\n",
            "else:\n",
            "   largest = num3\n",
            "print(f'largest:{largest}')\n",
            "\n",
            "\n",
            "# write a program to find and print the smallest among three numbers\n",
            "num1 = 10\n",
            "num2 = 12\n",
            "num3 = 14\n",
            "if (num1 <= num2) and (num1 <= num3):\n",
            "   smallest = num1\n",
            "elif (num2 <= num1) and (num2 <= num3):\n",
            "   smallest = num2\n",
            "else:\n",
            "   smallest = num3\n",
            "print(f'smallest:{smallest}')\n",
            "\n",
            "\n",
            "# Wr\n",
            "1103729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgKoAPUXpizS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "249O1xm277t3",
        "outputId": "1c347f69-6d1b-4499-ecbc-187eb49f581d"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>[num1 = 1.5, num2 = 6.3, sum = num1 + num2, pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a python function to add two user provi...</td>\n",
              "      <td>[def add_two_numbers(num1, num2):,     sum = n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the largest...</td>\n",
              "      <td>[num1 = 10, num2 = 12, num3 = 14, if (num1 &gt;= ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a program to find and print the smalles...</td>\n",
              "      <td>[num1 = 10, num2 = 12, num3 = 14, if (num1 &lt;= ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>write a program to print bit wise or of two n...</td>\n",
              "      <td>[a = 60, b = 13, c = a | b, print(\"or\", c), , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4991</th>\n",
              "      <td>write a program to print bit wise xor of two ...</td>\n",
              "      <td>[a = 60, b = 13, c = a ^ b, print(\"xor\", c), , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4992</th>\n",
              "      <td>write a program to calculate binary ones comp...</td>\n",
              "      <td>[a = 60, c = ~a, print(\"binary ones complement...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>write a program to binary left shift a number</td>\n",
              "      <td>[c = a &lt;&lt; 2, print(\"binary left shift\", c), , ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4994</th>\n",
              "      <td>write a program to binary right shift a number</td>\n",
              "      <td>[c = a &gt;&gt; 2, print(\"binary right shift\", c), ]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4995 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    src                                                trg\n",
              "0                                                                                                       []\n",
              "1             write a python program to add two numbers  [num1 = 1.5, num2 = 6.3, sum = num1 + num2, pr...\n",
              "2      write a python function to add two user provi...  [def add_two_numbers(num1, num2):,     sum = n...\n",
              "3      write a program to find and print the largest...  [num1 = 10, num2 = 12, num3 = 14, if (num1 >= ...\n",
              "4      write a program to find and print the smalles...  [num1 = 10, num2 = 12, num3 = 14, if (num1 <= ...\n",
              "...                                                 ...                                                ...\n",
              "4990   write a program to print bit wise or of two n...    [a = 60, b = 13, c = a | b, print(\"or\", c), , ]\n",
              "4991   write a program to print bit wise xor of two ...   [a = 60, b = 13, c = a ^ b, print(\"xor\", c), , ]\n",
              "4992   write a program to calculate binary ones comp...  [a = 60, c = ~a, print(\"binary ones complement...\n",
              "4993      write a program to binary left shift a number    [c = a << 2, print(\"binary left shift\", c), , ]\n",
              "4994     write a program to binary right shift a number     [c = a >> 2, print(\"binary right shift\", c), ]\n",
              "\n",
              "[4995 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdBCwGsI_mb-"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kZYHfhv_ouP",
        "outputId": "73c49190-05a4-485f-ed0a-7ba7275907c4"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2456KDRANWK"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMh6iD3eAizQ"
      },
      "source": [
        "def custom_tokenizer(nlp):\n",
        "    infix_re = re.compile(r'''[.\\,\\?\\:\\;\\...\\‘\\’\\`\\“\\”\\\"\\'\\(\\)\\[\\]\\{\\}\\*\\%\\^\\+\\-\\=\\<\\>\\|\\!(//)(\\n)(\\t)~]''')\n",
        "    prefix_re = compile_prefix_regex(nlp.Defaults.prefixes)\n",
        "    suffix_re = compile_suffix_regex(nlp.Defaults.suffixes)\n",
        "\n",
        "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                token_match=None)\n",
        "\n",
        "spacy_que = spacy.load('en_core_web_sm')\n",
        "spacy_ans = spacy.load('en_core_web_sm')\n",
        "spacy_ans.tokenizer = custom_tokenizer(spacy_ans)\n",
        "\n",
        "def tokenize_que(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    text = re.sub(r'#','',text).strip()\n",
        "    return [tok.text for tok in spacy_que.tokenizer(text)]\n",
        "\n",
        "def tokenize_ans(text):\n",
        "    \"\"\"\n",
        "    Tokenizes Code text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_ans.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXC-7vY0Cwsb"
      },
      "source": [
        "SRC = Field(tokenize = 'spacy', \n",
        "            eos_token = '<eos>',\n",
        "            init_token = '<sos>', \n",
        "            lower = True,\n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = 'spacy', \n",
        "            eos_token = '<eos>',\n",
        "            init_token = '<sos>', \n",
        "            lower = True,\n",
        "            batch_first = True)\n",
        "\n",
        "fields = [(\"src\", SRC), (\"trg\", TRG)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqoQHT1h2ux"
      },
      "source": [
        "fields = [(\"src\", SRC), (\"trg\", TRG)]\n",
        "example = [data.Example.fromlist([df.src[i],df.trg[i]], fields) for i in range(df.shape[0])] \n",
        "dataset = data.Dataset(example, fields)\n",
        "\n",
        "\n",
        "\n",
        "(train_data, valid_data, test_data) = dataset.split(split_ratio=[0.80, 0.10, 0.10], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQlCa5pXiybY",
        "outputId": "553743df-24b5-4a1d-8c2b-1fe271cd1b2f"
      },
      "source": [
        "print(vars(train_data.examples[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'src': [' ', 'write', 'a', 'program', 'that', 'adds', 'the', 'square', 'of', 'two', 'numbers', 'and', 'prints', 'it'], 'trg': ['a = 32', 'b = 21', 'result = a**2 + b**2', 'print(result)', '']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjWtM0MjjC65"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 1)\n",
        "TRG.build_vocab(train_data, min_freq = 1)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_VAIPapjJib",
        "outputId": "5c80df3d-f47c-4cd4-e112-ba59271edc87"
      },
      "source": [
        "print(\"Program_text Vocab size\", len(SRC.vocab))\n",
        "print(\"Program_code Vocab size\", len(TRG.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Program_text Vocab size 2314\n",
            "Program_code Vocab size 11795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNmHG9NOjQ62"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "     sort= False,\n",
        "     batch_size = BATCH_SIZE,\n",
        "     device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Un9TA5inDpt"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')\n",
        "def Tokenize(sentence):\n",
        "  sentence = str(sentence).replace('\\n', '\\t\\t')\n",
        "  return [tok.text for tok in spacy_en.tokenizer(sentence)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iQ46-NZTgXx"
      },
      "source": [
        "import gensim\n",
        "w2v_dim = 256\n",
        "w2v_min_count = 2\n",
        "w2v_window = 3\n",
        "target = []\n",
        "for sent in df['trg'].values:\n",
        "  sent_token = Tokenize(sent)\n",
        "  #sent_token = tokenize_ans(sent)\n",
        "  target.append(sent_token)\n",
        "w2v_model = gensim.models.Word2Vec(target, size = w2v_dim, window = w2v_window, min_count = w2v_min_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "fb685de4df9041cf834e9e5b2ae5c8c3",
            "0c596078e08e4d4b833c7f25f44521f1",
            "5f3dda8e79a343ebbaf1c89369fedb98",
            "90451e2d9f87463f858a93bf2f5ea1f6",
            "a727555182204a81b23c490bf6ec2d1a",
            "60ec1abeada94b3ba2fdfef284661b2b",
            "b767b5aad2234618b45305cca0d4164e",
            "a0e5c4d7e67b4eb99f8042d11e316567"
          ]
        },
        "id": "hCoP-pE1TzX9",
        "outputId": "7d2fb73c-b62f-4ed4-98c9-a34c9ff262e1"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "word2vec_vectors = []\n",
        "for token, idx in tqdm_notebook(TRG.vocab.stoi.items()):\n",
        "  if token in w2v_model.wv.vocab.keys():\n",
        "    word2vec_vectors.append(torch.FloatTensor(w2v_model[token]))\n",
        "  else:\n",
        "    word2vec_vectors.append(torch.zeros(w2v_dim))\n",
        "TRG.vocab.set_vectors(TRG.vocab.stoi, word2vec_vectors, w2v_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb685de4df9041cf834e9e5b2ae5c8c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11795.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEgJBpw9aRIe",
        "outputId": "81a018d8-d672-47fd-f612-3702fb076d6e"
      },
      "source": [
        "TRG.vocab.vectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JUnTAQ6UGk8"
      },
      "source": [
        "w2v_model.save('embeddings.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDK-VwOU1VS"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 255):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        #self.tok_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(Program_text.vocab.vectors))\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_dBA9LvU8UN"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTiJSUOKU_k7"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIXulxZcVCLX"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ANHDYJ2VEUO"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 pre_trained_emb,\n",
        "                 max_length = 255):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        #self.tok_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(Program_code.vocab.vectors))\n",
        "        self.pre_trained_emb = pre_trained_emb\n",
        "        self.tok_embedding = nn.Embedding.from_pretrained(self.pre_trained_emb)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "            \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8OPijdWVMfk"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxCNguX0VP20"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXVYVXkTeU_5"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "pre_trained_emb = torch.FloatTensor(TRG.vocab.vectors)\n",
        "\n",
        "enc = Encoder(INPUT_DIM,\n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device, \n",
        "              pre_trained_emb)\n",
        "\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ih_mdaoVmfT"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim()>1 and not isinstance(m,nn.Embedding):\n",
        "        nn.init.xavier_normal_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYkA4jf3VogT"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8CeuNllVqMH"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mp34iAzVr1B"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "        if isinstance(criterion, nn.CTCLoss):\n",
        "            output_lengths = output.shape[1]\n",
        "            target_lengths = trg.shape[1]-1\n",
        "            output = output.contiguous().permute(1,0,2)\n",
        "            trg = trg[:,1:].contiguous()\n",
        "            loss = criterion(output, trg, output_lengths, target_lengths)\n",
        "        else:\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        \n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dofxS1LyVy7J"
      },
      "source": [
        "def evaluate(model, iterator, criterion, metrics=None):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            if isinstance(criterion, nn.CTCLoss):\n",
        "                output_lengths = torch.full(size=(output.shape[0],), fill_value = output.shape[1], dtype=torch.long)\n",
        "                target_lengths = trg.shape[1]-1\n",
        "                output = output.contiguous().permute(1,0,2)\n",
        "                trg = trg[:,1:].contiguous()\n",
        "                loss = criterion(output, trg, output_lengths, target_lengths)\n",
        "\n",
        "            else:\n",
        "                output = output.contiguous().view(-1, output_dim)\n",
        "                trg = trg[:,1:].contiguous().view(-1)\n",
        "                loss = criterion(output, trg)\n",
        "            # compute bleu score\n",
        "            #if metrics is not None:\n",
        "                \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEjwW6C1V2Db"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUi7jaH5elJx"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMFJ68tee2MJ"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o7T3uKCe2Ip"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "#criterion = nn.CTCLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNcpdvFue5Ac",
        "outputId": "e88fd3a1-f5cb-4384-fed3-b86725db94b7"
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 4s\n",
            "\tTrain Loss: 7.944 | Train PPL: 2818.080\n",
            "\t Val. Loss: 7.529 |  Val. PPL: 1861.021\n",
            "Epoch: 02 | Time: 0m 3s\n",
            "\tTrain Loss: 7.142 | Train PPL: 1264.526\n",
            "\t Val. Loss: 7.552 |  Val. PPL: 1903.649\n",
            "Epoch: 03 | Time: 0m 4s\n",
            "\tTrain Loss: 6.928 | Train PPL: 1020.208\n",
            "\t Val. Loss: 7.572 |  Val. PPL: 1943.589\n",
            "Epoch: 04 | Time: 0m 3s\n",
            "\tTrain Loss: 6.748 | Train PPL: 852.729\n",
            "\t Val. Loss: 7.480 |  Val. PPL: 1771.403\n",
            "Epoch: 05 | Time: 0m 4s\n",
            "\tTrain Loss: 6.587 | Train PPL: 725.450\n",
            "\t Val. Loss: 7.524 |  Val. PPL: 1851.035\n",
            "Epoch: 06 | Time: 0m 3s\n",
            "\tTrain Loss: 6.465 | Train PPL: 642.123\n",
            "\t Val. Loss: 7.436 |  Val. PPL: 1696.643\n",
            "Epoch: 07 | Time: 0m 3s\n",
            "\tTrain Loss: 6.340 | Train PPL: 566.589\n",
            "\t Val. Loss: 7.431 |  Val. PPL: 1686.903\n",
            "Epoch: 08 | Time: 0m 4s\n",
            "\tTrain Loss: 6.209 | Train PPL: 497.346\n",
            "\t Val. Loss: 7.396 |  Val. PPL: 1629.466\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 6.058 | Train PPL: 427.380\n",
            "\t Val. Loss: 7.289 |  Val. PPL: 1464.261\n",
            "Epoch: 10 | Time: 0m 3s\n",
            "\tTrain Loss: 5.873 | Train PPL: 355.397\n",
            "\t Val. Loss: 7.236 |  Val. PPL: 1388.155\n",
            "Epoch: 11 | Time: 0m 4s\n",
            "\tTrain Loss: 5.734 | Train PPL: 309.234\n",
            "\t Val. Loss: 7.198 |  Val. PPL: 1336.442\n",
            "Epoch: 12 | Time: 0m 4s\n",
            "\tTrain Loss: 5.569 | Train PPL: 262.124\n",
            "\t Val. Loss: 7.124 |  Val. PPL: 1241.489\n",
            "Epoch: 13 | Time: 0m 4s\n",
            "\tTrain Loss: 5.403 | Train PPL: 222.152\n",
            "\t Val. Loss: 7.072 |  Val. PPL: 1179.033\n",
            "Epoch: 14 | Time: 0m 3s\n",
            "\tTrain Loss: 5.264 | Train PPL: 193.226\n",
            "\t Val. Loss: 7.004 |  Val. PPL: 1100.879\n",
            "Epoch: 15 | Time: 0m 4s\n",
            "\tTrain Loss: 5.073 | Train PPL: 159.579\n",
            "\t Val. Loss: 6.943 |  Val. PPL: 1035.431\n",
            "Epoch: 16 | Time: 0m 3s\n",
            "\tTrain Loss: 4.900 | Train PPL: 134.321\n",
            "\t Val. Loss: 6.865 |  Val. PPL: 957.733\n",
            "Epoch: 17 | Time: 0m 3s\n",
            "\tTrain Loss: 4.754 | Train PPL: 116.099\n",
            "\t Val. Loss: 6.791 |  Val. PPL: 889.531\n",
            "Epoch: 18 | Time: 0m 3s\n",
            "\tTrain Loss: 4.569 | Train PPL:  96.401\n",
            "\t Val. Loss: 6.739 |  Val. PPL: 844.592\n",
            "Epoch: 19 | Time: 0m 3s\n",
            "\tTrain Loss: 4.403 | Train PPL:  81.725\n",
            "\t Val. Loss: 6.682 |  Val. PPL: 797.728\n",
            "Epoch: 20 | Time: 0m 4s\n",
            "\tTrain Loss: 4.225 | Train PPL:  68.367\n",
            "\t Val. Loss: 6.626 |  Val. PPL: 754.622\n",
            "Epoch: 21 | Time: 0m 4s\n",
            "\tTrain Loss: 4.036 | Train PPL:  56.613\n",
            "\t Val. Loss: 6.572 |  Val. PPL: 714.642\n",
            "Epoch: 22 | Time: 0m 4s\n",
            "\tTrain Loss: 3.863 | Train PPL:  47.623\n",
            "\t Val. Loss: 6.500 |  Val. PPL: 664.925\n",
            "Epoch: 23 | Time: 0m 3s\n",
            "\tTrain Loss: 3.672 | Train PPL:  39.327\n",
            "\t Val. Loss: 6.467 |  Val. PPL: 643.297\n",
            "Epoch: 24 | Time: 0m 4s\n",
            "\tTrain Loss: 3.495 | Train PPL:  32.954\n",
            "\t Val. Loss: 6.410 |  Val. PPL: 607.875\n",
            "Epoch: 25 | Time: 0m 3s\n",
            "\tTrain Loss: 3.352 | Train PPL:  28.567\n",
            "\t Val. Loss: 6.413 |  Val. PPL: 609.534\n",
            "Epoch: 26 | Time: 0m 4s\n",
            "\tTrain Loss: 3.169 | Train PPL:  23.792\n",
            "\t Val. Loss: 6.311 |  Val. PPL: 550.409\n",
            "Epoch: 27 | Time: 0m 4s\n",
            "\tTrain Loss: 3.019 | Train PPL:  20.462\n",
            "\t Val. Loss: 6.292 |  Val. PPL: 540.083\n",
            "Epoch: 28 | Time: 0m 3s\n",
            "\tTrain Loss: 2.842 | Train PPL:  17.149\n",
            "\t Val. Loss: 6.295 |  Val. PPL: 542.002\n",
            "Epoch: 29 | Time: 0m 3s\n",
            "\tTrain Loss: 2.709 | Train PPL:  15.016\n",
            "\t Val. Loss: 6.274 |  Val. PPL: 530.418\n",
            "Epoch: 30 | Time: 0m 3s\n",
            "\tTrain Loss: 2.534 | Train PPL:  12.598\n",
            "\t Val. Loss: 6.219 |  Val. PPL: 502.272\n",
            "Epoch: 31 | Time: 0m 3s\n",
            "\tTrain Loss: 2.373 | Train PPL:  10.728\n",
            "\t Val. Loss: 6.247 |  Val. PPL: 516.254\n",
            "Epoch: 32 | Time: 0m 4s\n",
            "\tTrain Loss: 2.242 | Train PPL:   9.410\n",
            "\t Val. Loss: 6.200 |  Val. PPL: 492.523\n",
            "Epoch: 33 | Time: 0m 4s\n",
            "\tTrain Loss: 2.094 | Train PPL:   8.117\n",
            "\t Val. Loss: 6.196 |  Val. PPL: 490.857\n",
            "Epoch: 34 | Time: 0m 4s\n",
            "\tTrain Loss: 1.986 | Train PPL:   7.287\n",
            "\t Val. Loss: 6.186 |  Val. PPL: 486.111\n",
            "Epoch: 35 | Time: 0m 3s\n",
            "\tTrain Loss: 1.889 | Train PPL:   6.612\n",
            "\t Val. Loss: 6.210 |  Val. PPL: 497.621\n",
            "Epoch: 36 | Time: 0m 4s\n",
            "\tTrain Loss: 1.789 | Train PPL:   5.986\n",
            "\t Val. Loss: 6.262 |  Val. PPL: 524.526\n",
            "Epoch: 37 | Time: 0m 3s\n",
            "\tTrain Loss: 1.682 | Train PPL:   5.379\n",
            "\t Val. Loss: 6.247 |  Val. PPL: 516.453\n",
            "Epoch: 38 | Time: 0m 3s\n",
            "\tTrain Loss: 1.590 | Train PPL:   4.904\n",
            "\t Val. Loss: 6.289 |  Val. PPL: 538.440\n",
            "Epoch: 39 | Time: 0m 4s\n",
            "\tTrain Loss: 1.508 | Train PPL:   4.519\n",
            "\t Val. Loss: 6.298 |  Val. PPL: 543.243\n",
            "Epoch: 40 | Time: 0m 3s\n",
            "\tTrain Loss: 1.386 | Train PPL:   3.998\n",
            "\t Val. Loss: 6.343 |  Val. PPL: 568.339\n",
            "Epoch: 41 | Time: 0m 3s\n",
            "\tTrain Loss: 1.317 | Train PPL:   3.733\n",
            "\t Val. Loss: 6.331 |  Val. PPL: 561.451\n",
            "Epoch: 42 | Time: 0m 4s\n",
            "\tTrain Loss: 1.240 | Train PPL:   3.456\n",
            "\t Val. Loss: 6.397 |  Val. PPL: 600.042\n",
            "Epoch: 43 | Time: 0m 4s\n",
            "\tTrain Loss: 1.184 | Train PPL:   3.268\n",
            "\t Val. Loss: 6.446 |  Val. PPL: 629.912\n",
            "Epoch: 44 | Time: 0m 4s\n",
            "\tTrain Loss: 1.129 | Train PPL:   3.093\n",
            "\t Val. Loss: 6.444 |  Val. PPL: 628.939\n",
            "Epoch: 45 | Time: 0m 4s\n",
            "\tTrain Loss: 1.049 | Train PPL:   2.855\n",
            "\t Val. Loss: 6.493 |  Val. PPL: 660.578\n",
            "Epoch: 46 | Time: 0m 4s\n",
            "\tTrain Loss: 0.997 | Train PPL:   2.711\n",
            "\t Val. Loss: 6.510 |  Val. PPL: 672.059\n",
            "Epoch: 47 | Time: 0m 3s\n",
            "\tTrain Loss: 0.935 | Train PPL:   2.547\n",
            "\t Val. Loss: 6.617 |  Val. PPL: 747.481\n",
            "Epoch: 48 | Time: 0m 3s\n",
            "\tTrain Loss: 0.896 | Train PPL:   2.450\n",
            "\t Val. Loss: 6.607 |  Val. PPL: 740.555\n",
            "Epoch: 49 | Time: 0m 4s\n",
            "\tTrain Loss: 0.875 | Train PPL:   2.399\n",
            "\t Val. Loss: 6.667 |  Val. PPL: 786.264\n",
            "Epoch: 50 | Time: 0m 3s\n",
            "\tTrain Loss: 0.813 | Train PPL:   2.254\n",
            "\t Val. Loss: 6.689 |  Val. PPL: 803.639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZD6TOXIwPnl"
      },
      "source": [
        "import spacy\n",
        "def generate_code(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xba9pFjxwSUi",
        "outputId": "48600be7-ac59-433a-9971-c1761d3d7992"
      },
      "source": [
        "Question_text = 'write a python program to prints common letters in two input strings\\n '\n",
        "\n",
        "print(Question_text )\n",
        "\n",
        "translation, attention = generate_code(Question_text , SRC, TRG, model, device)\n",
        "\n",
        "for i in range(len(translation)):\n",
        "  print(translation[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "write a python program to prints common letters in two input strings\n",
            " \n",
            "s1='python'\n",
            "s2='schoolofai'\n",
            "a=list(set(s1)&set(s2))\n",
            "print(\"the common letters are:\")\n",
            "for i in a:\n",
            "    print(i)\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZDfXeC_wTjD",
        "outputId": "99f377d0-33b7-43d9-b284-0273fed6ff3d"
      },
      "source": [
        "import random\n",
        "\n",
        "for i in range(25):\n",
        "  print(\"++++++++++++++++++++++\\n\\n\\nExample\", i+1)\n",
        "  inf = random.randint(1,2500)\n",
        "  src = vars(train_data.examples[inf])['src']\n",
        "  print(' '.join(src))\n",
        "  translation, attention = generate_code(src , SRC, TRG, model, device)\n",
        "\n",
        "  for i in range(len(translation)):\n",
        "    print(end =\" \")\n",
        "    print(translation[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 1\n",
            "   generate 3 random integers between 100 and 999 which is divisible by 5\n",
            " import random\n",
            " print(\"generating 3 random integer number between 100 and 999 divisible by 5\")\n",
            " for num in range(3):\n",
            "     print(random.randrange(100, 999, 5), end=', ')\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 2\n",
            "  write a python program to prints common letters in two input strings\n",
            " s1='python'\n",
            " s2='schoolofai'\n",
            " a=list(set(s1)&set(s2))\n",
            " print(\"the common letters are:\")\n",
            " for i in a:\n",
            "     print(i)\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 3\n",
            "  96 write a python function that takes a number and returns an array of the number duplicated n times\n",
            " \n",
            " def duplicate_array(num, n):\n",
            "     num = [num] * n\n",
            "     return num\n",
            " \n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 4\n",
            "  write a python program to find area of circle\n",
            " pi = 3.14\n",
            " radius = float(6)\n",
            " area = pi * radius * radius\n",
            " circumference = 2 * pi * radius\n",
            " print(f'area of a circle {area}')\n",
            " print(f'circumference of a circle {circumference}')\n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 5\n",
            "  3 . python function to return the squareroot of a list of numbers\n",
            " def sqrt(n):\n",
            "    return [i**0.5 for i in range(n)]\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 6\n",
            "  write a python program to implement radix sort and print the sorted list for the below list\n",
            " def bubble_sort(alist):\n",
            "     if alist == []:\n",
            "         return\n",
            "         for j in range(0, i):\n",
            "         def key(alist, index):\n",
            "                 alist[j], alist[j + 1] = alist[j + 1], alist[j]\n",
            "                 no_swap = false\n",
            "         if no_swap:\n",
            "     exp = 0\n",
            " selection_sort(alist)\n",
            "         alist = counting_sort(alist, base - 1, key_factory(exp, base))\n",
            " bubble_sort(alist)\n",
            "     return alist\n",
            " \n",
            " \n",
            "     for i in range(len(alist)):\n",
            "         c[key(alist, i)] = c[key(alist, i)] + 1\n",
            "     c[0] = c[0] - 1\n",
            " print(alist)\n",
            " print(alist)\n",
            " print(alist)\n",
            "     for i in range(len(alist) - 1, -1, -1):\n",
            " print('sorted list: ', end='')\n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 7\n",
            "  define a class named american which has a static method called printnationality .\n",
            " class american(object):\n",
            " @staticmethod\n",
            " def printnationality():\n",
            " print (\"america\")\n",
            " anamerican = american()\n",
            " anamerican.printnationality()\n",
            " american.printnationality()\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 8\n",
            "  write a python program to swap tuple elements in list of tuples . print the output .\n",
            " test_list = [(3, 4), (6, 5), (7, 8)]\n",
            " res = [(sub[1], sub[0]) for sub in test_list]\n",
            " print(\"the swapped tuple list is : \" + str(res))\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 9\n",
            "  returns the number of times the specified element appears in the list\n",
            " vowels = ['a', 'e', 'i', 'o', 'i', 'u']\n",
            " count = vowels.count('i')\n",
            " print('the count of i is:', count)\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 10\n",
            "  write a python program to print unique numbers in a list\n",
            " numbers = [1, 2, 2, 3, 4, 4, 5, 6]\n",
            " unique = set(numbers)\n",
            " print(f'unique numbers: {list(unique)}')\n",
            " \n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 11\n",
            "  write a python function to return random selection from itertools.product(*args , * * kwds )\n",
            " def random_product(*args, repeat=1):\n",
            "     import random\n",
            "     pools = [tuple(pool) for pool in args] * repeat\n",
            "     return tuple(map(random.choice, pools))\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 12\n",
            "  write a function to calculate the displacement of an object with initial velocity u , time t and acceleration a\n",
            " def cal_final_velocity(initial_velocity:float,accelration:float,time:float)->float:\n",
            "     return initial_velocity*time + .5*accelration*(time)**2\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 13\n",
            "  define a class named american and its subclass newyorker .\n",
            " class american(object):\n",
            "     pass\n",
            " class newyorker(american):\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 14\n",
            "  write a python program to convert a list into a nested dictionary of keys .\n",
            " num_list = [1, 2, 3, 4]\n",
            " new_dict = current = {}\n",
            " for name in num_list:\n",
            " current[name] = {}\n",
            " current = current[name]\n",
            " print(new_dict)\n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 15\n",
            "  write a python program to do chained comparison\n",
            " a = 10\n",
            " print(1 < a < 50)\n",
            " print(10 == a < 20)\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 16\n",
            "  one by one yield next fibonacci number\n",
            "     while a < limit:\n",
            "         yield a\n",
            "         a, b = b, a + b\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 17\n",
            "  write a python program to get the maximum and minimum value in a dictionary\n",
            " my_dict = {'x':500, 'y':5874, 'z': 560}\n",
            " key_max = max(my_dict.keys(), key=(lambda k: my_dict[k]))\n",
            " key_min = min(my_dict.keys(), key=(lambda k: my_dict[k]))\n",
            " print('maximum value in a dictionary: ',my_dict[key_max])\n",
            " print('minimum value in a dictionary: ',my_dict[key_min])\n",
            " print('minimum value in a dictionary: ',my_dict[key_min])\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 18\n",
            "  iterate through columns\n",
            "    for j in range(len(x[0])):\n",
            "        result[j][i] = x[i][j]\n",
            " for r in result:\n",
            "    print(r)\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 19\n",
            "  write a program which can map ( ) to make a list whose elements are square of numbers between 1 and 20 ( both included ) .\n",
            " squarednumbers = map(lambda x: x**2, range(1,21))\n",
            " print(squarednumbers)\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 20\n",
            "  find the sum of the cube of each digit\n",
            " temp = num\n",
            " while temp > 0:\n",
            "    digit = temp % 10\n",
            "    sum += digit ** order\n",
            "    temp //= 10\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 21\n",
            "  write a python program to find index of min element\n",
            " lst = [40, 10, 20, 30]\n",
            " def minindex(lst):\n",
            "     return min(range(len(lst)), key=lst.__getitem__)\n",
            " print(minindex(lst))\n",
            " print(minindex(lst))\n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 22\n",
            "  write a function to merge dictionaries\n",
            " def merge1():\n",
            "     test_list1 = [{\"a\": 1, \"b\": 4}, {\"c\": 10, \"d\": 15},\n",
            "                   {\"f\": \"gfg\"}]\n",
            "     test_list2 = [{\"e\": 6}, {\"f\": 3, \"fg\": 10, \"h\": 1},\n",
            "                   {\"i\": 10}]\n",
            "     print(\"the original list 1 is : \" + str(test_list1))\n",
            "     print(\"the original list 2 is : \" + str(test_list2))\n",
            "     for idx in range(0, len(test_list1)):\n",
            "         id_keys = list(test_list1[idx].keys())\n",
            "         for key in test_list2[idx]:\n",
            "             if key not in id_keys:\n",
            "                 test_list1[idx][key] = test_list2[idx][key]\n",
            "     print(\"the merged dictionary list : \" + str(test_list1))\n",
            "             if key not in id_keys:\n",
            "             if key not in id_keys:\n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 23\n",
            "  write a python program to break a list into chunks of size n in python\n",
            " l = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            " n = 4\n",
            " x = [l[i:i + n] for i in range(0, len(l), n)]\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 24\n",
            "  write a python program to print a new set with all items from both sets by removing duplicates\n",
            " set1 = {10, 20, 30, 40, 50}\n",
            " set2 = {30, 40, 50, 60, 70}\n",
            " print(set1.union(set2))\n",
            " \n",
            " <eos>\n",
            "++++++++++++++++++++++\n",
            "\n",
            "\n",
            "Example 25\n",
            "write a python program to find the biggest character in a string\n",
            " bigchar = lambda word: reduce(lambda x,y: x if ord(x) > ord(y) else y, word)\n",
            " \n",
            " <eos>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}